import requests
import pandas as pd
import json
import math
import pdf2image
import pytesseract
from mpi4py import MPI
import os

'''
Reads the incomplete set of resolution text that is generated by generate_corpus.py
into a Pandas DataFrame and fills in the missing resolution text by:

1 - Converting PDF files into image files
2 - Reading image files by using Tesseract OCR Engine
3 - Inserting the extracted string into corresponding DataFrame cells
4 - Writing the complete DataFrame to a JSON file

Optical Character Recognition solution is required because some of the PDFs on the
UNGA website are scans of original documents and cannot be read by conventional PDF readers.
'''

comm = MPI.COMM_WORLD
size = comm.Get_size()
rank = comm.Get_rank()
name = MPI.Get_processor_name()

dirname=os.path.dirname

FILE_PATH = os.path.abspath(__file__)
ROOT_DIR = dirname(dirname(dirname(FILE_PATH)))
INIT_DATA_PATH = os.path.join(ROOT_DIR, 'data', 'initial')
INTER_DATA_PATH = os.path.join(ROOT_DIR, 'data', 'inter')
ERROR_LOG = os.path.join(ROOT_DIR, 'error-logs')


def complete_corpus(raw_corpus):
	errors = []
	for ind, k in raw_corpus.iterrows():
		if k['Text'] == '': # work only on incomplete resolutions
			for t in range(3): # try again if something returns an error
				try:
					url = k['url']
					req = requests.get(url)
					pages = pdf2image.convert_from_bytes(req.content) # converts pdf into image
					res = ''
					for page in pages:
						res += pytesseract.image_to_string(page) # uses OCR to convert image into string
					k['Text'] = res # fills in the incomplete cell with resolution text
					break
				except:
					if t == 2:
						errors.append(k['Resolution']) # keeps track of problematic resolutions
					continue

	return(raw_corpus, errors)

if __name__ == "__main__": 

	if rank == 0: 
		# read incomplete corpus
		raw_all = pd.read_json(os.path.join(INIT_DATA_PATH, 'unga_corpus_raw.json'))

		# partition the dataset for parallel processing
		n = math.ceil(len(raw_all) / size)
		raw_all = [raw_all[i * n:(i + 1) * n] for i in range((len(raw_all) + n - 1) // n )]
	else:
		raw_all = None

	raw_all = comm.scatter(raw_all, root=0)
	corpus, errors = complete_corpus(raw_all)
	corpus = comm.gather(corpus, root=0)
	errors = comm.gather(errors, root=0)

	if rank == 0: 
		errors = [i for j in errors for i in j]
		if len(errors) >= 1: # write errorred out resolutions to a JSON file
			with open(os.path.join(ERROR_LOG, 'ocr_errors.txt'), 'w') as err:
				json.dump(errors, err)

		corpus = pd.concat(corpus).reset_index(drop=True)
		 # write the complete dataset into a JSON file
		corpus.to_json(os.path.join(INTER_DATA_PATH, 'unga_corpus_complete.json'))